{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFID  Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Headlines</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Press</th>\n",
       "      <th>Date</th>\n",
       "      <th>Keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I served in Iraq and Afghanistan but the horro...</td>\n",
       "      <td>A WAR hero traumatised by the horrors of comba...</td>\n",
       "      <td>The Sun</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The forever war in Afghanistan is nowhere near...</td>\n",
       "      <td>Islamic State is seeking to overthrow the Tali...</td>\n",
       "      <td>ThePrint</td>\n",
       "      <td>2 weeks ago</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hell at Abbey Gate: Chaos, Confusion and Death...</td>\n",
       "      <td>In firsthand accounts, Afghan civilians and U....</td>\n",
       "      <td>ProPublica</td>\n",
       "      <td>1 month ago</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>‘A second Afghanistan’: Doubts over Russia’s w...</td>\n",
       "      <td>Russia's lack of progress in its war against U...</td>\n",
       "      <td>Al Jazeera</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Afghanistan: Former army general vows new war ...</td>\n",
       "      <td>Lt Gen Sami Sadat tells the BBC of planned ope...</td>\n",
       "      <td>BBC</td>\n",
       "      <td>1 week ago</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0                                          Headlines  \\\n",
       "0          0  I served in Iraq and Afghanistan but the horro...   \n",
       "1          1  The forever war in Afghanistan is nowhere near...   \n",
       "2          2  Hell at Abbey Gate: Chaos, Confusion and Death...   \n",
       "3          3  ‘A second Afghanistan’: Doubts over Russia’s w...   \n",
       "4          4  Afghanistan: Former army general vows new war ...   \n",
       "\n",
       "                                             Summary       Press         Date  \\\n",
       "0  A WAR hero traumatised by the horrors of comba...     The Sun    1 day ago   \n",
       "1  Islamic State is seeking to overthrow the Tali...    ThePrint  2 weeks ago   \n",
       "2  In firsthand accounts, Afghan civilians and U....  ProPublica  1 month ago   \n",
       "3  Russia's lack of progress in its war against U...  Al Jazeera   5 days ago   \n",
       "4  Lt Gen Sami Sadat tells the BBC of planned ope...         BBC   1 week ago   \n",
       "\n",
       "       Keyword  \n",
       "0  Afghanistan  \n",
       "1  Afghanistan  \n",
       "2  Afghanistan  \n",
       "3  Afghanistan  \n",
       "4  Afghanistan  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(\"data\\war-news.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5654 entries, 0 to 5653\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  5634 non-null   object\n",
      " 1   Headlines   5653 non-null   object\n",
      " 2   Summary     5653 non-null   object\n",
      " 3   Press       5653 non-null   object\n",
      " 4   Date        5653 non-null   object\n",
      " 5   Keyword     5653 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 265.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5653 entries, 0 to 5652\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  5633 non-null   object\n",
      " 1   Headlines   5653 non-null   object\n",
      " 2   Summary     5653 non-null   object\n",
      " 3   Press       5653 non-null   object\n",
      " 4   Date        5653 non-null   object\n",
      " 5   Keyword     5653 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 309.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with missing values in 'title' and 'summary' columns\n",
    "data = data.dropna(subset=['Headlines', 'Summary'])\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract titles and summaries from the DataFrame\n",
    "titles = data['Headlines'].tolist()\n",
    "summaries = data['Summary'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):  # Check if the input is a string\n",
    "        text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
    "        text = text.lower()\n",
    "        tokens = word_tokenize(text)\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "        return \" \".join(filtered_tokens)\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_titles = [preprocess_text(title) for title in titles]\n",
    "preprocessed_summaries = [preprocess_text(summary) for summary in summaries]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>TFID </b>\n",
    "<ol>\n",
    "<li> Representation: TF-IDF represents each document as a vector, where each dimension corresponds to a unique term in the entire corpus. </li>\n",
    "<li>Term Importance: It assigns weights to terms based on their frequency in a document relative to their frequency across all documents in the corpus. High weight is given to terms that are frequent in the document but not common across all documents. </li>\n",
    "<li>Document Comparison: TF-IDF vectors are used to calculate the similarity between documents. The similarity is based on the overlap of terms and their weights. </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature representation\n",
    "vectorizer = TfidfVectorizer()\n",
    "title_vectors = vectorizer.fit_transform(preprocessed_titles)\n",
    "summary_vectors = vectorizer.transform(preprocessed_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity calculation\n",
    "similarity_scores = cosine_similarity(title_vectors, summary_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 most similar pairs:\n",
      "Title: India and Pakistan fought 3 wars over Kashmir - here's why international \n",
      "law falls short to solve this territorial dispute\n",
      "Summary: India and Pakistan fought 3 wars over Kashmir - here's why international \n",
      "law falls short to solve this territorial dispute.\n",
      "Similarity score: 1.00\n",
      "\n",
      "Title: India and Pakistan fought 3 wars over Kashmir - here's why international \n",
      "law falls short to solve this territorial dispute\n",
      "Summary: An armed conflict in Kashmir has thwarted all attempts to solve it for \n",
      "three quarters of a century. Kashmir, an 85,806-square-mile valley...\n",
      "Similarity score: 1.00\n",
      "\n",
      "Title: The risk of nuclear war was already the highest since the Cuban Missile \n",
      "Crisis. Putin has made it far worse, former energy secretary says\n",
      "Summary: The risk of nuclear war was already the highest since the Cuban Missile \n",
      "Crisis. Putin has made it far worse, former energy secretary says. By.\n",
      "Similarity score: 1.00\n",
      "\n",
      "Title: Russia-Ukraine War Highlights: Quad countries accepted India's position on \n",
      "conflict in Ukraine, says Australia\n",
      "Summary: Russia-Ukraine War Highlights: Quad countries accepted India's position on \n",
      "conflict in Ukraine, says Australia. Profile image. By CNBC-TV18 |...\n",
      "Similarity score: 1.00\n",
      "\n",
      "Title: Understanding the Shadow War Between Israel and Iran\n",
      "Summary: Of the many conflicts in the Middle East, the one between Iran and Israel \n",
      "is the most potentially explosive. Iranian leaders periodically...\n",
      "Similarity score: 1.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print top 5 most similar pairs\n",
    "most_similar = [(i, j, similarity_scores[i][j]) for i, j in enumerate(similarity_scores.argsort(axis=1)[:,-1])]\n",
    "most_similar_sorted = sorted(most_similar, key=lambda x: x[2],reverse=True)\n",
    "print(\"Top 5 most similar pairs:\")\n",
    "for i, j, score in most_similar_sorted[:5]:\n",
    "  print(\"Title: {}\\nSummary: {}\\nSimilarity score: {:.2f}\\n\".format(titles[i], summaries[i], score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Word2Vec</b>\n",
    "<ol>\n",
    "<li>Representation: Word2Vec represents each word as a dense vector in a continuous vector space. It captures the semantic relationships between words.</li>\n",
    "<li>Term Similarity: Word2Vec is trained on large corpora to learn word embeddings such that semantically similar words have similar vector representations.</li>\n",
    "<li>Document Representation: Document vectors can be obtained by averaging or combining the word vectors of the words in the document.</li>\n",
    "<li>Document Comparison: Similarity between documents is calculated based on the similarity of their word vectors. It captures the semantic similarity between documents.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load pre-trained word embeddings\n",
    "word2vec_model = KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin.gz\", binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_model = KeyedVectors.load_word2vec_format(\"glove.6B/glove.6B.300d.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word embedding matrices\n",
    "title_embeddings = np.array([word2vec_model[word] for word in preprocessed_titles if word in word2vec_model])\n",
    "summary_embeddings = np.array([glove_model[word] for word in preprocessed_summaries if word in glove_model])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate cosine similarity\n",
    "similarity_scores = cosine_similarity(title_embeddings, summary_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print top 5 most similar pairs\n",
    "most_similar = [(i, j, similarity_scores[i][j]) for i, j in enumerate(similarity_scores.argsort(axis=1)[:,-1])]\n",
    "most_similar_sorted = sorted(most_similar, key=lambda x: x[2],reverse=True)\n",
    "print(\"Top 5 most similar pairs:\")\n",
    "for i, j, score in most_similar_sorted[:5]:\n",
    "  print(\"Title: {}\\nSummary: {}\\nSimilarity score: {:.2f}\\n\".format(titles[i], summaries[i], score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print preprocessed titles and summaries\n",
    "for title, summary in zip(preprocessed_titles, preprocessed_summaries):\n",
    "    print(f\"Preprocessed Title: {title}\")\n",
    "    print(f\"Preprocessed Summary: {summary}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the Word2Vec Model  \n",
    "example_index =1  \n",
    "title_word_vectors = [word2vec_model.get_vector(word) for word in preprocessed_titles[example_index].split() if word in word2vec_model.key_to_index]\n",
    "summary_word_vectors = [word2vec_model.get_vector(word) for word in preprocessed_summaries[example_index].split() if word in word2vec_model.key_to_index]\n",
    "\n",
    "print(f\"Word Vectors for Example {example_index} Title: {title_word_vectors}\")\n",
    "\n",
    "print(f\"Word Vectors for Example {example_index} Summary: {summary_word_vectors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Universal Sentence Encoder (USE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_hub import load\n",
    "\n",
    "use_model = load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "\n",
    "title_embeddings = use_model(preprocessed_titles)\n",
    "summary_embeddings = use_model(preprocessed_summaries)\n",
    "\n",
    "similarity_scores = cosine_similarity(title_embeddings, summary_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print top 5 most similar pairs\n",
    "most_similar = [(i, j, similarity_scores[i][j]) for i, j in enumerate(similarity_scores.argsort(axis=1)[:,-1])]\n",
    "most_similar_sorted = sorted(most_similar, key=lambda x: x[2],reverse=True)\n",
    "print(\"Top 5 most similar pairs:\")\n",
    "for i, j, score in most_similar_sorted[:5]:\n",
    "  print(\"Title: {}\\nSummary: {}\\nSimilarity score: {:.2f}\\n\".format(titles[i], summaries[i], score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
