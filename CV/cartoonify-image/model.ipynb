{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-08-22T03:53:39.552611Z","iopub.status.busy":"2023-08-22T03:53:39.552232Z","iopub.status.idle":"2023-08-22T03:53:39.560426Z","shell.execute_reply":"2023-08-22T03:53:39.559378Z","shell.execute_reply.started":"2023-08-22T03:53:39.552580Z"},"trusted":true},"outputs":[],"source":["import time\n","import re"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-08-22T03:53:39.876437Z","iopub.status.busy":"2023-08-22T03:53:39.875823Z","iopub.status.idle":"2023-08-22T03:53:43.599750Z","shell.execute_reply":"2023-08-22T03:53:43.598766Z","shell.execute_reply.started":"2023-08-22T03:53:39.876401Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import torch\n","from torchvision import datasets\n","from torch.utils.data import DataLoader\n","from torchvision import transforms\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-08-22T03:53:44.561482Z","iopub.status.busy":"2023-08-22T03:53:44.561113Z","iopub.status.idle":"2023-08-22T03:53:44.572194Z","shell.execute_reply":"2023-08-22T03:53:44.571299Z","shell.execute_reply.started":"2023-08-22T03:53:44.561443Z"},"trusted":true},"outputs":[],"source":["import utils\n","from transformer_net import TransformerNet\n","from vgg import Vgg16"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-08-22T03:53:44.574128Z","iopub.status.busy":"2023-08-22T03:53:44.573696Z","iopub.status.idle":"2023-08-22T03:53:44.580778Z","shell.execute_reply":"2023-08-22T03:53:44.579491Z","shell.execute_reply.started":"2023-08-22T03:53:44.574091Z"},"trusted":true},"outputs":[],"source":["# PARAMS\n","\n","SEED = 128\n","IMAGE_SIZE = 256\n","LR = 0.001\n","EPOCHS = 2\n","CONTENT_WEIGHT = 1e5\n","STYLE_WEIGHT = 1e10\n","BATCH_SIZE = 4\n","LOG_INTERVAL = 500\n","CHECKPOINT_INTERVAL = 2000\n","CONTENT_SCALE = None\n","MODEL_PATH = 'data/style1/'\n","DATASET_PATH = 'data/dataset'\n","STYLE_IMAGE = 'data/style1/style.jpg'\n","\n","CONTENT_IMAGE = 'data/original.jpg'\n","model = 'data/style1/nst.model'\n","OUTPUT_IMAGE = 'data/output1.png'"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-08-22T03:53:44.582867Z","iopub.status.busy":"2023-08-22T03:53:44.582412Z","iopub.status.idle":"2023-08-22T03:53:44.603341Z","shell.execute_reply":"2023-08-22T03:53:44.602193Z","shell.execute_reply.started":"2023-08-22T03:53:44.582833Z"},"trusted":true},"outputs":[],"source":["def train():\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    np.random.seed(SEED)\n","    torch.manual_seed(SEED)\n","\n","    transform = transforms.Compose([\n","        transforms.Resize(IMAGE_SIZE),\n","        transforms.CenterCrop(IMAGE_SIZE),\n","        transforms.ToTensor(),\n","        transforms.Lambda(lambda x: x.mul(255))\n","    ])\n","    train_dataset = datasets.ImageFolder(DATASET_PATH, transform)\n","    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n","    \n","    # TransformerNet\n","    transformer = TransformerNet().to(device)\n","    optimizer = torch.optim.Adam(transformer.parameters(), LR)\n","    mse_loss = torch.nn.MSELoss()\n","\n","    # VGG\n","    vgg = Vgg16(requires_grad=False).to(device)\n","    style_transform = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Lambda(lambda x: x.mul(255))\n","    ])\n","    style = utils.load_image(STYLE_IMAGE)\n","    style = style_transform(style)\n","    style = style.repeat(BATCH_SIZE, 1, 1, 1).to(device)\n","\n","    features_style = vgg(utils.normalize_batch(style))\n","    gram_style = [utils.gram_matrix(y) for y in features_style]\n","\n","\n","    # Training\n","    for epoch in range(EPOCHS):\n","        transformer.train()\n","        agg_content_loss = 0.\n","        agg_style_loss = 0.\n","        count = 0\n","        for batch_id, (x, _) in enumerate(train_loader):\n","            n_batch = len(x)\n","            count += n_batch\n","            optimizer.zero_grad()\n","\n","            x = x.to(device)\n","            y = transformer(x)\n","\n","            x = utils.normalize_batch(x)\n","            y = utils.normalize_batch(y)\n","\n","            features_x = vgg(x)\n","            features_y = vgg(y)\n","\n","            content_loss = CONTENT_WEIGHT * mse_loss(features_y.relu2_2, features_x.relu2_2)\n","\n","            style_loss = 0.\n","            for feat_y, gram_s in zip(features_y, gram_style):\n","                gram_y = utils.gram_matrix(feat_y)\n","                style_loss += mse_loss(gram_y, gram_s[:n_batch, :, :])\n","            style_loss *= STYLE_WEIGHT\n","\n","            total_loss = content_loss + style_loss\n","            total_loss.backward()\n","            optimizer.step()\n","\n","            agg_content_loss += content_loss.item()\n","            agg_style_loss += style_loss.item()\n","\n","            if (batch_id + 1) % LOG_INTERVAL == 0:\n","                mesg = \"{}\\tEpoch {}:\\t[{}/{}]\\tcontent: {:.6f}\\tstyle: {:.6f}\\ttotal: {:.6f}\".format(\n","                    time.ctime(), epoch + 1, count, len(train_loader.dataset),\n","                                  agg_content_loss / (batch_id + 1),\n","                                  agg_style_loss / (batch_id + 1),\n","                                  (agg_content_loss + agg_style_loss) / (batch_id + 1)\n","                )\n","                print(mesg)\n","            \n","    \n","    # save model\n","    transformer.eval().cpu()\n","    save_model_filename = \"epoch_\" + str(EPOCHS) + \"_\" + str(time.ctime()).replace(' ', '_') + \"_\" + str(\n","        STYLE_IMAGE.split('/')[-1].split('.')[0]) + \"_\" + str(CONTENT_WEIGHT) + \"_\" + str(STYLE_WEIGHT) + \".model\"\n","    save_model_path = os.path.join(MODEL_PATH, save_model_filename)\n","    torch.save(transformer.state_dict(), save_model_path)\n","\n","    print(\"\\nDone, trained model saved at\", save_model_path)\n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-08-22T03:53:44.619707Z","iopub.status.busy":"2023-08-22T03:53:44.619313Z","iopub.status.idle":"2023-08-22T03:53:44.632035Z","shell.execute_reply":"2023-08-22T03:53:44.631045Z","shell.execute_reply.started":"2023-08-22T03:53:44.619673Z"},"trusted":true},"outputs":[],"source":["def stylize():\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    content_image = utils.load_image(CONTENT_IMAGE)\n","    content_transform = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Lambda(lambda x: x.mul(255))\n","    ])\n","\n","    content_image = content_transform(content_image)\n","    content_image = content_image.unsqueeze(0).to(device)\n","\n","    with torch.no_grad():\n","        style_model = TransformerNet()\n","        state_dict = torch.load(model)\n","        \n","        for k in list(state_dict.keys()):\n","            if re.search(r'in\\d+\\.running_(mean|var)$', k):\n","                del state_dict[k]\n","        style_model.load_state_dict(state_dict)\n","        style_model.to(device)\n","        style_model = torch.nn.DataParallel(style_model)\n","        output = style_model(content_image).cpu()\n","    utils.save_image(OUTPUT_IMAGE, output[0])"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\n","KeyboardInterrupt\n","\n"]}],"source":["train()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-22T04:00:03.215680Z","iopub.status.busy":"2023-08-22T04:00:03.215314Z","iopub.status.idle":"2023-08-22T04:00:03.362100Z","shell.execute_reply":"2023-08-22T04:00:03.361091Z","shell.execute_reply.started":"2023-08-22T04:00:03.215650Z"},"trusted":true},"outputs":[],"source":["stylize()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":4}
