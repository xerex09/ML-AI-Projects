{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Forecasting for Temperature Data\n",
    "\n",
    "This notebook demonstrates time series forecasting using NASA temperature data. We'll explore the data, visualize patterns, and implement both statistical (SARIMA) and deep learning (LSTM) forecasting models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataframe = pd.read_csv(\"data/power_nasa.csv\")\n",
    "dataframe.info()\n",
    "\n",
    "# Display the first few rows to understand the data structure\n",
    "display(dataframe.head())\n",
    "\n",
    "# Basic statistics\n",
    "display(dataframe.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization - Yearly Temperature Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the dataframe by year\n",
    "grouped_df = dataframe.groupby('YEAR')\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "# Plot the graph for each year\n",
    "for year, group in grouped_df:\n",
    "    plt.plot(group['DOY'], group['T2M'], label=str(year))\n",
    "\n",
    "# Set the labels and title\n",
    "plt.xlabel('Day of Year')\n",
    "plt.ylabel('Temperature (T2M)')\n",
    "plt.title('Temperature vs Day of Year for Every Year')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Year Temperature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Filter the dataframe for the year 2020\n",
    "year_2020_df = dataframe[dataframe['YEAR'] == 2020]\n",
    "\n",
    "print(f\"Data points for year 2020: {len(year_2020_df)}\")\n",
    "# Plot the temperature values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(year_2020_df['DOY'], year_2020_df['T2M'])\n",
    "plt.xlabel('Day of Year')\n",
    "plt.ylabel('Temperature (T2M)')\n",
    "plt.title('Temperature vs Day of Year for the Year 2020')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the correlation matrix is stored in the variable 'correlation_matrix'\n",
    "# You can replace it with the actual variable name in your notebook\n",
    "\n",
    "correlation_matrix = dataframe.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Plot the correlation matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(correlation_matrix, cmap='coolwarm', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title('Correlation Matrix')\n",
    "plt.xticks(range(len(correlation_matrix.columns)), correlation_matrix.columns, rotation=90)\n",
    "plt.yticks(range(len(correlation_matrix.columns)), correlation_matrix.columns)\n",
    "\n",
    "# Add correlation values as text annotations\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(len(correlation_matrix.columns)):\n",
    "        plt.text(j, i, f'{correlation_matrix.iloc[i, j]:.2f}', \n",
    "                 ha='center', va='center', \n",
    "                 color='white' if abs(correlation_matrix.iloc[i, j]) > 0.5 else 'black')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation for Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your DataFrame is named df\n",
    "df = dataframe.copy()\n",
    "\n",
    "# Convert the date columns to a datetime object (if not already done)\n",
    "df['DATE'] = pd.to_datetime(df[['YEAR', 'DOY']].astype(str).apply('-'.join, 1), format='%Y-%j')\n",
    "df.set_index('DATE', inplace=True)\n",
    "\n",
    "# Drop unnecessary columns for forecasting\n",
    "df.drop(columns=['YEAR', 'DOY'], inplace=True)\n",
    "\n",
    "# Check the dataframe\n",
    "print(df.head())\n",
    "\n",
    "# Display more info about the prepared dataframe\n",
    "print(f\"\\nDataframe shape: {df.shape}\")\n",
    "print(\"\\nDataframe index info:\")\n",
    "print(f\"Start date: {df.index.min()}\")\n",
    "print(f\"End date: {df.index.max()}\")\n",
    "print(f\"Total days: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SARIMA Time Series Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "   \n",
    "\n",
    "    # Split data into train and test\n",
    "    train_size = int(len(df) * 0.8)\n",
    "    train_data = df[:train_size]\n",
    "    test_data = df[train_size:]\n",
    "\n",
    "    print(f\"Training data: {train_data.index.min()} to {train_data.index.max()} ({len(train_data)} days)\")\n",
    "    print(f\"Testing data: {test_data.index.min()} to {test_data.index.max()} ({len(test_data)} days)\")\n",
    "\n",
    "    # Define the model\n",
    "    model = SARIMAX(train_data['T2M'], order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))\n",
    "\n",
    "    # Fit the model\n",
    "    model_fit = model.fit(disp=False)\n",
    "\n",
    "    # Summary of the model\n",
    "    print(model_fit.summary())\n",
    "\n",
    "    # Forecast for the test period\n",
    "    forecast = model_fit.forecast(steps=len(test_data))\n",
    "    forecast_index = test_data.index\n",
    "\n",
    "    # Plot the forecast vs actual\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(train_data.index, train_data['T2M'], label='Training Data', color='blue')\n",
    "    plt.plot(test_data.index, test_data['T2M'], label='Actual Test Data', color='green')\n",
    "    plt.plot(forecast_index, forecast, label='SARIMA Forecast', color='red', linestyle='--')\n",
    "    plt.title('SARIMA Model: Temperature Forecast vs Actual')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Temperature (T2M)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse_sarima = mean_squared_error(test_data['T2M'], forecast)\n",
    "    mae_sarima = mean_absolute_error(test_data['T2M'], forecast)\n",
    "    rmse_sarima = np.sqrt(mse_sarima)\n",
    "    print(f'Mean Squared Error: {mse_sarima:.4f}')\n",
    "    print(f'Mean Absolute Error: {mae_sarima:.4f}')\n",
    "    print(f'Root Mean Squared Error: {rmse_sarima:.4f}')\n",
    "    \n",
    "except ModuleNotFoundError as e:\n",
    "\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"\\nPlease run the cell above to install the required packages, then restart the kernel and run this cell again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "   \n",
    "\n",
    "    # Scale the data\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(df[[\"T2M\"]])\n",
    "\n",
    "    # Prepare the data for LSTM\n",
    "    def create_dataset(data, time_step=1):\n",
    "        X, Y = [], []\n",
    "        for i in range(len(data) - time_step):\n",
    "            X.append(data[i:i + time_step])\n",
    "            Y.append(data[i + time_step])\n",
    "        return np.array(X), np.array(Y)\n",
    "\n",
    "    # Define the time step (window size)\n",
    "    time_step = 30\n",
    "\n",
    "    # Create the dataset\n",
    "    X, Y = create_dataset(scaled_data, time_step)\n",
    "\n",
    "    # Define the train-test split point\n",
    "    train_size = int(len(X) * 0.8)\n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    Y_train, Y_test = Y[:train_size], Y[train_size:]\n",
    "\n",
    "    print(f\"X_train shape: {X_train.shape}, Y_train shape: {Y_train.shape}\")\n",
    "    print(f\"X_test shape: {X_test.shape}, Y_test shape: {Y_test.shape}\")\n",
    "\n",
    "    # Build the LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, return_sequences=True, input_shape=(time_step, 1)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(64, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    # Early stopping to prevent overfitting\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    # Train the model with early stopping and validation split\n",
    "    history = model.fit(\n",
    "        X_train, Y_train,\n",
    "        batch_size=32,\n",
    "        epochs=50,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Plot the training history\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('LSTM Model Training History')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    # Get predictions\n",
    "    train_predict = model.predict(X_train)\n",
    "    test_predict = model.predict(X_test)\n",
    "\n",
    "    # Inverse transform to get actual temperature values\n",
    "    train_predict = scaler.inverse_transform(train_predict)\n",
    "    test_predict = scaler.inverse_transform(test_predict)\n",
    "    Y_train_actual = scaler.inverse_transform(Y_train)\n",
    "    Y_test_actual = scaler.inverse_transform(Y_test)\n",
    "\n",
    "    # Create timestamps for plotting\n",
    "    train_timestamps = df.index[time_step:train_size+time_step]\n",
    "    test_timestamps = df.index[train_size+time_step:train_size+time_step+len(test_predict)]\n",
    "\n",
    "    # Plot the predictions\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(df.index, df['T2M'], 'b-', label='Actual Temperature', alpha=0.5)\n",
    "    plt.plot(train_timestamps, train_predict, 'r--', label='Training Predictions')\n",
    "    plt.plot(test_timestamps, test_predict, 'g--', label='Testing Predictions')\n",
    "    plt.title('LSTM Model: Temperature Predictions vs Actual')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Temperature (T2M)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse_lstm = mean_squared_error(Y_test_actual, test_predict)\n",
    "    mae_lstm = mean_absolute_error(Y_test_actual, test_predict)\n",
    "    rmse_lstm = np.sqrt(mse_lstm)\n",
    "    print(f'Mean Squared Error: {mse_lstm:.4f}')\n",
    "    print(f'Mean Absolute Error: {mae_lstm:.4f}')\n",
    "    print(f'Root Mean Squared Error: {rmse_lstm:.4f}')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"\\nThis could be due to missing TensorFlow. If that's the case, please run:\")\n",
    "    print(\"!pip install tensorflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Check if the variables exist\n",
    "    if 'mse_sarima' not in locals() or 'mse_lstm' not in locals():\n",
    "        # If the model cells failed to run, use placeholder values\n",
    "        print(\"Warning: Model metrics not found. Using placeholder values for comparison.\")\n",
    "        # Use placeholder values\n",
    "        mse_sarima = mae_sarima = rmse_sarima = float('nan')\n",
    "        mse_lstm = mae_lstm = rmse_lstm = float('nan')\n",
    "    \n",
    "    # Create a comparison dataframe\n",
    "    models = ['SARIMA', 'LSTM']\n",
    "    metrics = {\n",
    "        'MSE': [mse_sarima, mse_lstm],\n",
    "        'MAE': [mae_sarima, mae_lstm],\n",
    "        'RMSE': [rmse_sarima, rmse_lstm]\n",
    "    }\n",
    "\n",
    "    comparison_df = pd.DataFrame(metrics, index=models)\n",
    "    display(comparison_df)\n",
    "\n",
    "    # Check if any values are NaN before plotting\n",
    "    if not comparison_df.isna().any().any():\n",
    "        # Visualize the comparison\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        comparison_df.plot(kind='bar', figsize=(10, 6))\n",
    "        plt.title('Model Performance Comparison')\n",
    "        plt.ylabel('Error Value')\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        plt.xticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Conclusion\n",
    "        print(\"Conclusion:\")\n",
    "        best_model = \"SARIMA\" if mse_sarima < mse_lstm else \"LSTM\"\n",
    "        print(f\"The {best_model} model performed better for this temperature forecasting task.\")\n",
    "        print(\"This could be due to the nature of temperature data, which typically has strong seasonal patterns.\")\n",
    "    else:\n",
    "        print(\"Cannot generate comparison plot due to missing metrics. Please run the model cells successfully first.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in comparison: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
